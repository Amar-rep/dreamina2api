import _ from "lodash";
import { PassThrough } from "stream";

import APIException from "@/lib/exceptions/APIException.ts";
import EX from "@/api/consts/exceptions.ts";
import logger from "@/lib/logger.ts";
import util from "@/lib/util.ts";
import { generateImages, DEFAULT_MODEL } from "./images.ts";
import { generateVideo, DEFAULT_MODEL as DEFAULT_VIDEO_MODEL } from "./videos.ts";
import { DreaminaErrorHandler, withRetry } from "@/lib/error-handler.ts";
import { RETRY_CONFIG } from "@/api/consts/common.ts";

/**
 * è§£æžæ¨¡åž‹
 *
 * @param model æ¨¡åž‹åç§°
 * @returns æ¨¡åž‹ä¿¡æ¯
 */
function parseModel(model: string) {
  const [_model, size] = model.split(":");
  const [_, width, height] = /(\d+)[\W\w](\d+)/.exec(size || "") ?? [];
  return {
    model: _model,
    width: size ? Math.ceil(parseInt(width) / 2) * 2 : 1024,
    height: size ? Math.ceil(parseInt(height) / 2) * 2 : 1024,
  };
}

/**
 * æ£€æµ‹æ˜¯å¦ä¸ºè§†é¢‘ç”Ÿæˆè¯·æ±‚
 *
 * @param model æ¨¡åž‹åç§°
 * @returns æ˜¯å¦ä¸ºè§†é¢‘ç”Ÿæˆè¯·æ±‚
 */
function isVideoModel(model: string) {
  return model.startsWith("dreamina-video");
}

/**
 * åŒæ­¥å¯¹è¯è¡¥å…¨
 *
 * @param messages å‚è€ƒgptç³»åˆ—æ¶ˆæ¯æ ¼å¼ï¼Œå¤šè½®å¯¹è¯è¯·å®Œæ•´æä¾›ä¸Šä¸‹æ–‡
 * @param refreshToken ç”¨äºŽåˆ·æ–°access_tokençš„refresh_token
 * @param assistantId æ™ºèƒ½ä½“IDï¼Œé»˜è®¤ä½¿ç”¨dreaminaåŽŸç‰ˆ
 * @param retryCount é‡è¯•æ¬¡æ•°
 */
export async function createCompletion(
  messages: any[],
  refreshToken: string,
  _model = DEFAULT_MODEL,
  retryCount = 0
) {
  return (async () => {
    if (messages.length === 0)
      throw new APIException(EX.API_REQUEST_PARAMS_INVALID, "æ¶ˆæ¯ä¸èƒ½ä¸ºç©º");

    const { model, width, height } = parseModel(_model);
    logger.info(messages);

    // æ£€æŸ¥æ˜¯å¦ä¸ºè§†é¢‘ç”Ÿæˆè¯·æ±‚
    if (isVideoModel(_model)) {
      try {
        // è§†é¢‘ç”Ÿæˆ
        logger.info(`å¼€å§‹ç”Ÿæˆè§†é¢‘ï¼Œæ¨¡åž‹: ${_model}`);
        const videoUrl = await generateVideo(
          _model,
          messages[messages.length - 1].content,
          {
            width,
            height,
            resolution: "720p",
          },
          refreshToken
        );

        logger.info(`è§†é¢‘ç”ŸæˆæˆåŠŸï¼ŒURL: ${videoUrl}`);
        return {
          id: util.uuid(),
          model: _model,
          object: "chat.completion",
          choices: [
            {
              index: 0,
              message: {
                role: "assistant",
                content: `![video](${videoUrl})\n`,
              },
              finish_reason: "stop",
            },
          ],
          usage: { prompt_tokens: 1, completion_tokens: 1, total_tokens: 2 },
          created: util.unixTimestamp(),
        };
      } catch (error: any) {
        logger.error(`è§†é¢‘ç”Ÿæˆå¤±è´¥: ${error.message}`);
        if (error instanceof APIException) {
          throw error;
        }

        return {
          id: util.uuid(),
          model: _model,
          object: "chat.completion",
          choices: [
            {
              index: 0,
              message: {
                role: "assistant",
                content: `ç”Ÿæˆè§†é¢‘å¤±è´¥: ${error.message}\n\nå¦‚æžœæ‚¨åœ¨Dreaminaå®˜ç½‘çœ‹åˆ°å·²ç”Ÿæˆçš„è§†é¢‘ï¼Œå¯èƒ½æ˜¯èŽ·å–ç»“æžœæ—¶å‡ºçŽ°äº†é—®é¢˜ï¼Œè¯·å‰å¾€Dreaminaå®˜ç½‘æŸ¥çœ‹ã€‚`,
              },
              finish_reason: "stop",
            },
          ],
          usage: { prompt_tokens: 1, completion_tokens: 1, total_tokens: 2 },
          created: util.unixTimestamp(),
        };
      }
    } else {
      // å›¾åƒç”Ÿæˆ
      const imageUrls = await generateImages(
        model,
        messages[messages.length - 1].content,
        {
          width,
          height,
        },
        refreshToken
      );

      return {
        id: util.uuid(),
        model: _model || model,
        object: "chat.completion",
        choices: [
          {
            index: 0,
            message: {
              role: "assistant",
              content: imageUrls.reduce(
                (acc, url, i) => acc + `![image_${i}](${url})\n`,
                ""
              ),
            },
            finish_reason: "stop",
          },
        ],
        usage: { prompt_tokens: 1, completion_tokens: 1, total_tokens: 2 },
        created: util.unixTimestamp(),
      };
    }
  })().catch((err) => {
    if (retryCount < RETRY_CONFIG.MAX_RETRY_COUNT) {
      logger.error(`Response error: ${err.stack}`);
      logger.warn(`Try again after ${RETRY_CONFIG.RETRY_DELAY / 1000}s...`);
      return (async () => {
        await new Promise((resolve) => setTimeout(resolve, RETRY_CONFIG.RETRY_DELAY));
        return createCompletion(messages, refreshToken, _model, retryCount + 1);
      })();
    }
    throw err;
  });
}

/**
 * æµå¼å¯¹è¯è¡¥å…¨
 *
 * @param messages å‚è€ƒgptç³»åˆ—æ¶ˆæ¯æ ¼å¼ï¼Œå¤šè½®å¯¹è¯è¯·å®Œæ•´æä¾›ä¸Šä¸‹æ–‡
 * @param refreshToken ç”¨äºŽåˆ·æ–°access_tokençš„refresh_token
 * @param assistantId æ™ºèƒ½ä½“IDï¼Œé»˜è®¤ä½¿ç”¨dreaminaåŽŸç‰ˆ
 * @param retryCount é‡è¯•æ¬¡æ•°
 */
export async function createCompletionStream(
  messages: any[],
  refreshToken: string,
  _model = DEFAULT_MODEL,
  retryCount = 0
) {
  return (async () => {
    const { model, width, height } = parseModel(_model);
    logger.info(messages);

    const stream = new PassThrough();

    if (messages.length === 0) {
      logger.warn("æ¶ˆæ¯ä¸ºç©ºï¼Œè¿”å›žç©ºæµ");
      stream.end("data: [DONE]\n\n");
      return stream;
    }

    // æ£€æŸ¥æ˜¯å¦ä¸ºè§†é¢‘ç”Ÿæˆè¯·æ±‚
    if (isVideoModel(_model)) {
      // è§†é¢‘ç”Ÿæˆ
      stream.write(
        "data: " +
          JSON.stringify({
            id: util.uuid(),
            model: _model,
            object: "chat.completion.chunk",
            choices: [
              {
                index: 0,
                delta: { role: "assistant", content: "ðŸŽ¬ Video generation in progress...\nThis may take 1-2 minutes, please wait" },
                finish_reason: null,
              },
            ],
          }) +
          "\n\n"
      );

      logger.info(`å¼€å§‹ç”Ÿæˆè§†é¢‘ï¼Œæç¤ºè¯: ${messages[messages.length - 1].content}`);

      const progressInterval = setInterval(() => {
        if (stream.destroyed) {
          clearInterval(progressInterval);
          return;
        }
        stream.write(
          "data: " +
            JSON.stringify({
              id: util.uuid(),
              model: _model,
              object: "chat.completion.chunk",
              choices: [
                {
                  index: 0,
                  delta: { role: "assistant", content: "." },
                  finish_reason: null,
                },
              ],
            }) +
            "\n\n"
        );
      }, 5000);

      const timeoutId = setTimeout(() => {
        clearInterval(progressInterval);
        logger.warn(`è§†é¢‘ç”Ÿæˆè¶…æ—¶ï¼ˆ2åˆ†é’Ÿï¼‰ï¼Œæç¤ºç”¨æˆ·å‰å¾€Dreaminaå®˜ç½‘æŸ¥çœ‹`);
        if (!stream.destroyed) {
          stream.write(
            "data: " +
              JSON.stringify({
                id: util.uuid(),
                model: _model,
                object: "chat.completion.chunk",
                choices: [
                  {
                    index: 1,
                    delta: {
                      role: "assistant",
                      content: "\n\nVideo generation is taking longer than expected (2 minutes elapsed).\n\nPlease check Dreamina website for your video:\n1. Visit https://dreamina.capcut.com/ai-tool/video/generate\n2. Log in and check your creation history\n3. If the video is generated, you can download or share it directly",
                    },
                    finish_reason: "stop",
                  },
                ],
              }) +
              "\n\n"
          );
        }
      }, 2 * 60 * 1000);

      stream.on('close', () => {
        clearInterval(progressInterval);
        clearTimeout(timeoutId);
        logger.debug('è§†é¢‘ç”Ÿæˆæµå·²å…³é—­ï¼Œå®šæ—¶å™¨å·²æ¸…ç†');
      });

      logger.info(`å¼€å§‹ç”Ÿæˆè§†é¢‘ï¼Œæ¨¡åž‹: ${_model}, æç¤ºè¯: ${messages[messages.length - 1].content.substring(0, 50)}...`);

      stream.write(
        "data: " +
          JSON.stringify({
            id: util.uuid(),
            model: _model,
            object: "chat.completion.chunk",
            choices: [
              {
                index: 0,
                delta: {
                  role: "assistant",
                  content: "\n\nðŸŽ¬ Video generation started, this may take a few minutes...",
                },
                finish_reason: null,
              },
            ],
          }) +
          "\n\n"
      );

      generateVideo(
        _model,
        messages[messages.length - 1].content,
        { width, height, resolution: "720p" },
        refreshToken
      )
        .then((videoUrl) => {
          clearInterval(progressInterval);
          clearTimeout(timeoutId);

          logger.info(`è§†é¢‘ç”ŸæˆæˆåŠŸï¼ŒURL: ${videoUrl}`);

          if (!stream.destroyed && stream.writable) {
            stream.write(
              "data: " +
                JSON.stringify({
                  id: util.uuid(),
                  model: _model,
                  object: "chat.completion.chunk",
                  choices: [
                    {
                      index: 1,
                      delta: {
                        role: "assistant",
                        content: `\n\nâœ… Video generation complete!\n\n![video](${videoUrl})\n\nYou can:\n1. View the video above\n2. Download or share using: ${videoUrl}`,
                      },
                      finish_reason: null,
                    },
                  ],
                }) +
                "\n\n"
            );

            stream.write(
              "data: " +
                JSON.stringify({
                  id: util.uuid(),
                  model: _model,
                  object: "chat.completion.chunk",
                  choices: [
                    {
                      index: 2,
                      delta: {
                        role: "assistant",
                        content: "",
                      },
                      finish_reason: "stop",
                    },
                  ],
                }) +
                "\n\n"
            );
            stream.end("data: [DONE]\n\n");
          } else {
            logger.debug('è§†é¢‘ç”Ÿæˆå®Œæˆï¼Œä½†æµå·²å…³é—­ï¼Œè·³è¿‡å†™å…¥');
          }
        })
        .catch((err) => {
          clearInterval(progressInterval);
          clearTimeout(timeoutId);

          logger.error(`è§†é¢‘ç”Ÿæˆå¤±è´¥: ${err.message}`);
          logger.error(`é”™è¯¯è¯¦æƒ…: ${JSON.stringify(err)}`);

          let errorMessage = `âš ï¸ Video generation encountered an issue: ${err.message}`;

          if (err.message.includes("åŽ†å²è®°å½•ä¸å­˜åœ¨")) {
            errorMessage += "\n\nPossible causes:\n1. Request was sent but API couldn't retrieve history\n2. Video generation service temporarily unavailable\n\nPlease check Dreamina website: https://dreamina.capcut.com/ai-tool/video/generate";
          } else if (err.message.includes("èŽ·å–è§†é¢‘ç”Ÿæˆç»“æžœè¶…æ—¶")) {
            errorMessage += "\n\nVideo generation may still be in progress but timeout exceeded.\n\nPlease check Dreamina website: https://dreamina.capcut.com/ai-tool/video/generate";
          } else {
            errorMessage += "\n\nPlease check Dreamina website for your creation history: https://dreamina.capcut.com/ai-tool/video/generate";
          }

          if (err.historyId) {
            errorMessage += `\n\nHistory ID: ${err.historyId}`;
          }

          if (!stream.destroyed && stream.writable) {
            stream.write(
              "data: " +
                JSON.stringify({
                  id: util.uuid(),
                  model: _model,
                  object: "chat.completion.chunk",
                  choices: [
                    {
                      index: 1,
                      delta: {
                        role: "assistant",
                        content: `\n\n${errorMessage}`,
                      },
                      finish_reason: "stop",
                    },
                  ],
                }) +
                "\n\n"
            );
            stream.end("data: [DONE]\n\n");
          } else {
            logger.debug('è§†é¢‘ç”Ÿæˆå¤±è´¥ï¼Œä½†æµå·²å…³é—­ï¼Œè·³è¿‡é”™è¯¯ä¿¡æ¯å†™å…¥');
          }
        });
    } else {
      // å›¾åƒç”Ÿæˆ
      stream.write(
        "data: " +
          JSON.stringify({
            id: util.uuid(),
            model: _model || model,
            object: "chat.completion.chunk",
            choices: [
              {
                index: 0,
                delta: { role: "assistant", content: "ðŸŽ¨ Image generation in progress..." },
                finish_reason: null,
              },
            ],
          }) +
          "\n\n"
      );

      generateImages(
        model,
        messages[messages.length - 1].content,
        { width, height },
        refreshToken
      )
        .then((imageUrls) => {
          if (!stream.destroyed && stream.writable) {
            for (let i = 0; i < imageUrls.length; i++) {
              const url = imageUrls[i];
              stream.write(
                "data: " +
                  JSON.stringify({
                    id: util.uuid(),
                    model: _model || model,
                    object: "chat.completion.chunk",
                    choices: [
                      {
                        index: i + 1,
                        delta: {
                          role: "assistant",
                          content: `![image_${i}](${url})\n`,
                        },
                        finish_reason: i < imageUrls.length - 1 ? null : "stop",
                      },
                    ],
                  }) +
                  "\n\n"
              );
            }
            stream.write(
              "data: " +
                JSON.stringify({
                  id: util.uuid(),
                  model: _model || model,
                  object: "chat.completion.chunk",
                  choices: [
                    {
                      index: imageUrls.length + 1,
                      delta: {
                        role: "assistant",
                        content: "Image generation complete!",
                      },
                      finish_reason: "stop",
                    },
                  ],
                }) +
                "\n\n"
            );
            stream.end("data: [DONE]\n\n");
          } else {
            logger.debug('å›¾åƒç”Ÿæˆå®Œæˆï¼Œä½†æµå·²å…³é—­ï¼Œè·³è¿‡å†™å…¥');
          }
        })
        .catch((err) => {
          if (!stream.destroyed && stream.writable) {
            stream.write(
              "data: " +
                JSON.stringify({
                  id: util.uuid(),
                  model: _model || model,
                  object: "chat.completion.chunk",
                  choices: [
                    {
                      index: 1,
                      delta: {
                        role: "assistant",
                        content: `Image generation failed: ${err.message}`,
                      },
                      finish_reason: "stop",
                    },
                  ],
                }) +
                "\n\n"
            );
            stream.end("data: [DONE]\n\n");
          } else {
            logger.debug('å›¾åƒç”Ÿæˆå¤±è´¥ï¼Œä½†æµå·²å…³é—­ï¼Œè·³è¿‡é”™è¯¯ä¿¡æ¯å†™å…¥');
          }
        });
    }
    return stream;
  })().catch((err) => {
    if (retryCount < RETRY_CONFIG.MAX_RETRY_COUNT) {
      logger.error(`Response error: ${err.stack}`);
      logger.warn(`Try again after ${RETRY_CONFIG.RETRY_DELAY / 1000}s...`);
      return (async () => {
        await new Promise((resolve) => setTimeout(resolve, RETRY_CONFIG.RETRY_DELAY));
        return createCompletionStream(
          messages,
          refreshToken,
          _model,
          retryCount + 1
        );
      })();
    }
    throw err;
  });
}
